{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune: train on random init CNN and original prepared dataset\n",
        "\n",
        "Original prepared dataset is the code in `finetuning/readme.md` which samples at 250 hz, 65 seconds.\n",
        "\n",
        "Now we try training on an uninitialized CNN.\n",
        "\n",
        "We do this by *not* passing in the `--weights-file` parameter to `finetuning.trainer`.\n",
        "\n",
        "It's not quite clear whether we need to explicitly fill the CNN with randomized weights or if the CNN network weights themselves are already randomized when no model weights are loaded into it."
      ],
      "metadata": {
        "id": "v1XRxBLDglRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNqG2WkWgjH3"
      },
      "outputs": [],
      "source": [
        "# You may also manually mount drive by clicking on folder icon in left sidebar\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = '/content/drive/MyDrive/DLHProject'"
      ],
      "metadata": {
        "id": "M7jO-g3ziDbB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPO = PROJECT_ROOT + '/Danielgitrepo'"
      ],
      "metadata": {
        "id": "-zVHB1B1iDd3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $REPO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL9h8ntdiDhp",
        "outputId": "60be4842-68b4-4087-ff17-787cc37c3a72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1vlUILM7cToH5CoX1x0kWRpe55MbBogS-/Project/Danielgitrepo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKEvhfLriULt",
        "outputId": "fc84bb47-b10c-4792-d28e-7d2736e84efa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.66.2)\n",
            "Collecting wfdb (from -r requirements.txt (line 8))\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (5.5.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 1)) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb->-r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 9)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 9)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 9)) (6.3.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 10)) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 10)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 1)) (0.43.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb->-r requirements.txt (line 8)) (2024.2.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 9)) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 9)) (23.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->-r requirements.txt (line 8)) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->-r requirements.txt (line 9)) (4.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->-r requirements.txt (line 9)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->-r requirements.txt (line 1)) (3.2.2)\n",
            "Installing collected packages: jedi, wfdb\n",
            "Successfully installed jedi-0.19.1 wfdb-4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = PROJECT_ROOT + '/data'"
      ],
      "metadata": {
        "id": "J_SX1ghHiUH0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls $DATA_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXzD5t0riUEl",
        "outputId": "9c9a8bef-8182-46fb-bdf7-1d776a738195"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "icentia11k\t\t     physionet\t\t\t\t physionet_preread\n",
            "icentia11k_subset\t     physionet_250hz_15000pad_norm_True  session_checkpoint.dat\n",
            "icentia11k_subset_corrupted  physionet_data.zip\t\t\t temp.torrent\n",
            "icentia11k_subset_unzipped   physionet_finetune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we run the finetuning trainer, we should prepare job output directory. We make a sister `jobs` directory to the data directory.\n",
        "\n",
        "It should be noted that finetune trainer should also create the jobs directory for you by Line49:\n",
        "\n",
        "```python\n",
        "os.makedirs(str(args.job_dir), exist_ok=True)\n",
        "```\n",
        "\n",
        "But I think it is a good practice to just set up the directory structure yourself instead of just assuming the code will do it all for you."
      ],
      "metadata": {
        "id": "oOPCMQFLilP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JOB_DIR = PROJECT_ROOT + '/jobs'\n",
        "! mkdir -p $JOB_DIR"
      ],
      "metadata": {
        "id": "dJN-qWu-iUBv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls $PROJECT_ROOT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hQjn1eUinOD",
        "outputId": "363b751a-21a9-429e-9ce3-b32908faa50f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Archive\t\t\t Mylesgitrepo\n",
            "'Copy of DL4H_Team_0'\t\t'Notes from last year’s Class.gdoc'\n",
            " Danielgitrepo\t\t\t proposal\n",
            " data\t\t\t\t Sched:Daniel:M-F1700+,Sa-SuAllday:Vacay:None.gdoc\n",
            " data_partial_download\t\t Sched:Myles:M-Su0300-1900:VacayMar01-Mar17.gdoc\n",
            " DownloadData.ipynb\t\t Sched:Ted:M-F1700+,Sa-Su1500+:Vacay:Mar31-Apr06.gdoc\n",
            " ECG_TransferLearningPaper.pdf\t Scheduling.gdoc\n",
            " ExampleNotebook.ipynb\t\t'Spring24: Project Grading rubrik.gdoc'\n",
            " jobs\t\t\t\t Tedgitrepo\n",
            "'Meeting Notes.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that while we did create the `jobs/` directory, we will defer the creation of fine tuning train specific output directory to the trainer code.\n",
        "\n",
        "So for this experiment, we will write the fine tune results out to `jobs/finetune_random_cnn_original_data`. The name indicates 2 things\n",
        "\n",
        "1. Random pretrained CNN used\n",
        "2. We use the same preprocessing steps the authors suggest in their README. Which again is **not** aligned with what they say in the paper."
      ],
      "metadata": {
        "id": "ChKcV_grjkNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other discrepancies\n",
        "\n",
        "This is the exact code that the authors say we should run finetuning with:\n",
        "\n",
        "```shell script\n",
        "python -m finetuning.trainer \\\n",
        "--job-dir \"jobs/af_classification\" \\\n",
        "--train \"data/physionet_train.pkl\" \\\n",
        "--test \"data/physionet_test.pkl\" \\\n",
        "--weights-file \"jobs/beat_classification/resnet18.weights\" \\\n",
        "--val-size 0.0625 \\\n",
        "--arch \"resnet18\" \\\n",
        "--batch-size 64 \\\n",
        "--epochs 200\n",
        "```\n",
        "\n",
        "The discrepancies:\n",
        "\n",
        "1. `--val-size` indicates what fraction of the train dataset should be held out for validation at the end of epochs. The above value is 6.25 percent. However in paper, they say 5 percent used.\n",
        "\n",
        "2. `--val-metric` is NOT specified. The default value is `loss`. The help message describes this parameter as\n",
        "\n",
        "  > Validation metric used to find the best model at each epoch.\n",
        "\n",
        "  However, in the paper, the authors say that they use macro F1 score to evaluate on validation set and also to select the best model.\n",
        "\n",
        "## Reproducibility\n",
        "\n",
        "The trainer code also has a `--seed` parameter, which is not provided in the above code snippet.\n",
        "\n",
        "For our own benefit, we shall set `--seed 2024` for reproducibility in *our* own work."
      ],
      "metadata": {
        "id": "Og6V6_NXkJ_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_dir = JOB_DIR + '/finetune_random_cnn_original_data'\n",
        "train = DATA_DIR + '/physionet_finetune/physionet_train.pkl'\n",
        "test = DATA_DIR + '/physionet_finetune/physionet_test.pkl'\n",
        "\n",
        "print(f\"job_dir: {job_dir}\")\n",
        "print(f\"train: {train}\")\n",
        "print(f\"test: {test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96dJL5rglyVq",
        "outputId": "d2659fd4-4ef8-4a46-f21b-79d2454264db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "job_dir: /content/drive/MyDrive/DLHProject/jobs/finetune_random_cnn_original_data\n",
            "train: /content/drive/MyDrive/DLHProject/data/physionet_finetune/physionet_train.pkl\n",
            "test: /content/drive/MyDrive/DLHProject/data/physionet_finetune/physionet_test.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%% time\n",
        "# We've removed --weights-file parameter.\n",
        "# We've set --val-size to 5 percent\n",
        "# We've set --val-metric to f1\n",
        "# We've set --seed to 2024\n",
        "# We've set --verbose to see what's going on\n",
        "! python -m finetuning.trainer \\\n",
        "--job-dir $job_dir \\\n",
        "--train $train \\\n",
        "--test $test \\\n",
        "--val-size 0.05 \\\n",
        "--val-metric \"f1\" \\\n",
        "--arch \"resnet18\" \\\n",
        "--batch-size 64 \\\n",
        "--epochs 200 \\\n",
        "--seed 2024 \\\n",
        "--verbose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQSa8mSljD39",
        "outputId": "623e48ef-757b-4ec3-eaf9-0720de056057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-03 06:18:54.463963: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-03 06:18:54.464042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-03 06:18:54.467260: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-03 06:18:54.479800: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-03 06:18:56.088625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Creating working directory in /content/drive/MyDrive/DLHProject/jobs/finetune_random_cnn_original_data\n",
            "Setting random state 2024\n",
            "Loading train data from /content/drive/MyDrive/DLHProject/data/physionet_finetune/physionet_train.pkl ...\n",
            "Split data into train 94.99% and validation 5.01%\n",
            "Loading test data from /content/drive/MyDrive/DLHProject/data/physionet_finetune/physionet_test.pkl ...\n",
            "Train data shape: (6480, 16384, 1)\n",
            "2024-04-03 06:19:32.429668: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 849346560 exceeds 10% of free system memory.\n",
            "Building model ...\n",
            "# model parameters: 4,494,532\n",
            "2024-04-03 06:19:36.723964: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 849346560 exceeds 10% of free system memory.\n",
            "2024-04-03 06:19:38.464672: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 849346560 exceeds 10% of free system memory.\n",
            "2024-04-03 06:19:39.478173: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "2024-04-03 06:19:39.513007: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 849346560 exceeds 10% of free system memory.\n",
            "Epoch 1/200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qd5EA-NFjD7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gBKO_kPbjD-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDwcki_AjEAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}