{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1XRxBLDglRi"
      },
      "source": [
        "# Finetune: weights from pre-training with 20% of pre-training data\n",
        "\n",
        "In this notebook, we perform full finetuning on the PhysioNet dataset using a  ResNet18 with weights from 20% of pre-training data. This will be compared with the baseline result of randomly initialized ResNet18.\n",
        "\n",
        "## Computational Requirements\n",
        "\n",
        "We run this notebook in Google Colab Pro to utilize GPU resources. We perform finetuning using the **V100 GPU**.\n",
        "\n",
        "## Data\n",
        "\n",
        "We have prepared the PhysioNet data in a separate notebook ([Github](https://github.com/myles-i/DLH_TransferLearning/blob/master/jupyter_notebooks/finetuning_explore.ipynb)). That notebook generates _train_ and _test_ datasets.\n",
        "\n",
        "In our case, the datasets are saved to our Google Drive at these paths:\n",
        "\n",
        "1. `/content/drive/MyDrive/Project/data/physionet_finetune/physionet_train.pkl`\n",
        "2. `/content/drive/MyDrive/Project/data/physionet_finetune/physionet_test.pkl`\n",
        "\n",
        "On this data, the preprocessing is as follows:\n",
        "1. Downsample the PhysioNet data to 250 hz\n",
        "2. Pad recordings to ~65 second length\n",
        "3. Normalize the recordings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdto6uVnwRoS"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNqG2WkWgjH3",
        "outputId": "0c220ce5-4504-4ec0-d796-1b69c7898383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# You may also manually mount drive by clicking on folder icon in left sidebar\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDppmL8e9XEv"
      },
      "source": [
        "### Clone code repo\n",
        "\n",
        "Assuming this notebook is run on Colab Pro, please clone our repo to the instance.\n",
        "\n",
        "Sample commands to run in Colab Pro Terminal:\n",
        "\n",
        "```bash\n",
        "$ cd /root\n",
        "# enter your username and github PAT\n",
        "$ git clone https://github.com/myles-i/DLH_TransferLearning.git\n",
        "$ cd DLH_TransferLearning\n",
        "```\n",
        "\n",
        "We will assume the code to run is on `master` branch.\n",
        "\n",
        "### Install dependencies\n",
        "\n",
        "We will install the dependencies from the `requirements.txt` file in the cloned repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlxdqFc_C1Lm",
        "outputId": "4cb48001-be62-4e9e-f8aa-2704c13b43eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root\n",
            "fatal: destination path 'DLH_TransferLearning' already exists and is not an empty directory.\n",
            "/root/DLH_TransferLearning\n"
          ]
        }
      ],
      "source": [
        "%cd /root\n",
        "! git clone https://github.com/myles-i/DLH_TransferLearning.git\n",
        "%cd DLH_TransferLearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zVHB1B1iDd3",
        "outputId": "edf4692e-5d24-4d92-e0fb-1638c06da072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/DLH_TransferLearning\n"
          ]
        }
      ],
      "source": [
        "REPO = '/root/DLH_TransferLearning/'\n",
        "%cd $REPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hKEvhfLriULt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa1PrAkNxk53"
      },
      "source": [
        "## Finetuning\n",
        "\n",
        "Below we set up the paths to the:\n",
        "1. `DATA_DIR`: location where the input files are\n",
        "2. `JOB_DIR`: location where to save the output of the finetuning (model weights, history, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M7jO-g3ziDbB"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = '/content/drive/MyDrive/DLHProject'\n",
        "DATA_DIR = PROJECT_ROOT + '/data'\n",
        "JOB_DIR = PROJECT_ROOT + '/jobs'\n",
        "#! mkdir -p $JOB_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOPCMQFLilP-"
      },
      "source": [
        "Next, we set up the actual input and output paths relative to the `DATA_DIR` and `JOB_DIR`, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atsAS6BlygqP",
        "outputId": "e0ab4c28-bc6f-467f-d4e2-e12247e12ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: /content/drive/MyDrive/DLHProject/data/physionet_finetune_spectrogram_nodb/physionet_train.pkl\n",
            "test: /content/drive/MyDrive/DLHProject/data/physionet_finetune_spectrogram_nodb/physionet_test.pkl\n",
            "job_dir: /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram\n"
          ]
        }
      ],
      "source": [
        "train = DATA_DIR + '/physionet_finetune_spectrogram_nodb/physionet_train.pkl'\n",
        "test = DATA_DIR + '/physionet_finetune_spectrogram_nodb/physionet_test.pkl'\n",
        "job_name = 'finetune_pretrain_20_weights_65sec_spectrogram'\n",
        "job_dir = JOB_DIR + '/' + job_name\n",
        "\n",
        "print(f\"train: {train}\")\n",
        "print(f\"test: {test}\")\n",
        "print(f\"job_dir: {job_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "96dJL5rglyVq",
        "outputId": "fa792e75-ce4b-4c89-d47f-1cd9bbe94f4b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'job_dir = JOB_DIR + \\'/finetune_random_cnn_original_data_with_f1\\'\\ntrain = DATA_DIR + \\'/physionet_finetune/physionet_train.pkl\\'\\ntest = DATA_DIR + \\'/physionet_finetune/physionet_test.pkl\\'\\n\\nprint(f\"job_dir: {job_dir}\")\\nprint(f\"train: {train}\")\\nprint(f\"test: {test}\")'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"job_dir = JOB_DIR + '/finetune_random_cnn_original_data_with_f1'\n",
        "train = DATA_DIR + '/physionet_finetune/physionet_train.pkl'\n",
        "test = DATA_DIR + '/physionet_finetune/physionet_test.pkl'\n",
        "\n",
        "print(f\"job_dir: {job_dir}\")\n",
        "print(f\"train: {train}\")\n",
        "print(f\"test: {test}\")\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ897PYWDSqe"
      },
      "source": [
        "Since we have pretrained our ResNet18, let's extract its weights from a model checkpoint. We will then load the weights to ResNet18 at the beginning of fine tuning stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnqsgAjuExkQ",
        "outputId": "eea2501e-5690-4e7b-c083-104c97273714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "environment.yml  finetune_runner.py  jupyter_notebooks\tpretraining  README.md\trequirements.txt\n",
            "example.ipynb\t finetuning\t     LICENSE\t\tproposal     report\ttransplant\n"
          ]
        }
      ],
      "source": [
        "! cd $CHECKPOINT_FILE\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmdsr6NuDRwd",
        "outputId": "cc89f91a-b256-4f05-9855-5177f79f8413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# magic module reload\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from pretraining.utils import get_pretrained_weights\n",
        "\n",
        "\n",
        "CHECKPOINT_FILE = PROJECT_ROOT + '/jobs/spectrogram/pretraining/16epochs_to_20percent_nodb/epoch_16'\n",
        "WEIGHTS_FILE = JOB_DIR + '/spectrogram/pretraining/prepared_for_finetuning_nodb/pre_trained_20_resnet18_2d.weights'\n",
        "\n",
        "resnet18 = get_pretrained_weights(\n",
        "    checkpoint_file=CHECKPOINT_FILE + '/model.weights',\n",
        "    task='beat',\n",
        "    arch='resnet18_2d')\n",
        "resnet18.save_weights(WEIGHTS_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXvWxLRPyzc3"
      },
      "source": [
        "The paper authors provide us this script that will perform the finetuning. We will run it below and expand on the meaning of the parameter values.\n",
        "- `--weights-file $WEIGHTS_FILE`: Path to pretrained weights or a checkpoint of the model to be used for model initialization.\n",
        "\n",
        "- `--val-size 0.0625`: This is the percentage of the train set size to set aside for the validation set.\n",
        "\n",
        "  Note that the PhysioNet data was already split 80-20 train-test. The paper uses 5 percent of the full dataset for validation. We get this via $0.0625 * 0.8 = 0.05$\n",
        "- `--val-metric \"f1\"`: Use macro F1 score to evaluate performance on validation set and to find the best model at each epoch.\n",
        "- `--arch \"resnet18\"` means we are using ResNet18 CNN.\n",
        "- `--batch-size 128` we found this value through trial and error that maximizes the utilization of the V100 GPU's 16 GB RAM.\n",
        "- `--epochs 200` This is taken from the paper.\n",
        "- `--seed 2024` this is the random seed used in splitting the train set into validation. This is for reproducibility.\n",
        "- `--verbose` this prints out the finetuning progress epoch by epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQSa8mSljD39",
        "outputId": "168a2edd-6a10-4d95-da26-e3823b9ba375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-04 15:16:13.594451: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-04 15:16:13.594501: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-04 15:16:13.595764: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-04 15:16:14.528967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Creating working directory in /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram\n",
            "Setting random state 2024\n",
            "Loading train data from /content/drive/MyDrive/DLHProject/data/physionet_finetune_spectrogram_nodb/physionet_train.pkl ...\n",
            "Split data into train 93.74% and validation 6.26%\n",
            "Loading test data from /content/drive/MyDrive/DLHProject/data/physionet_finetune_spectrogram_nodb/physionet_test.pkl ...\n",
            "Train data shape: (6395, 128, 512, 1)\n",
            "2024-05-04 15:16:59.734348: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-05-04 15:16:59.735882: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3352821760 exceeds 10% of free system memory.\n",
            "2024-05-04 15:17:02.876878: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3352821760 exceeds 10% of free system memory.\n",
            "Building model ...\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <transplant.modules.resnet2d.ResnetBlock object at 0x7c66770c0a90>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "# model parameters: 11,186,692\n",
            "Loading weights from file /content/drive/MyDrive/DLHProject/jobs/jobs/spectrogram/pretraining/prepared_for_finetuning_nodb/pre_trained_20_resnet18_2d.weights ...\n",
            "2024-05-04 15:17:08.933663: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3352821760 exceeds 10% of free system memory.\n",
            "2024-05-04 15:17:10.893922: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3352821760 exceeds 10% of free system memory.\n",
            "2024-05-04 15:17:12.863035: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3352821760 exceeds 10% of free system memory.\n",
            "Epoch 1/200\n",
            "2024-05-04 15:17:22.401187: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:22.473772: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1714835843.828928   12425 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2024-05-04 15:17:30.072862: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:30.097696: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:38.372985: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:38.436815: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:40.849789: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:40.874312: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:40.907039: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-04 15:17:40.971569: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00001: f1 improved from -inf to 0.41433, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 30s - loss: 0.6677 - acc: 0.7400 - val_loss: 0.7148 - val_acc: 0.6885 - f1: 0.4143 - 30s/epoch - 608ms/step\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00002: f1 (0.16388) did not improve from 0.41433\n",
            "50/50 - 8s - loss: 0.4322 - acc: 0.8413 - val_loss: 1.8240 - val_acc: 0.2998 - f1: 0.1639 - 8s/epoch - 155ms/step\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00003: f1 (0.19755) did not improve from 0.41433\n",
            "50/50 - 8s - loss: 0.3835 - acc: 0.8558 - val_loss: 1.6412 - val_acc: 0.3279 - f1: 0.1975 - 8s/epoch - 155ms/step\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00004: f1 (0.34095) did not improve from 0.41433\n",
            "50/50 - 8s - loss: 0.3430 - acc: 0.8752 - val_loss: 1.4660 - val_acc: 0.5738 - f1: 0.3410 - 8s/epoch - 155ms/step\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00005: f1 improved from 0.41433 to 0.51622, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.3129 - acc: 0.8841 - val_loss: 0.7026 - val_acc: 0.8080 - f1: 0.5162 - 9s/epoch - 170ms/step\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00006: f1 (0.48991) did not improve from 0.51622\n",
            "50/50 - 8s - loss: 0.2887 - acc: 0.8929 - val_loss: 0.7704 - val_acc: 0.8080 - f1: 0.4899 - 8s/epoch - 156ms/step\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00007: f1 improved from 0.51622 to 0.60454, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.2686 - acc: 0.9015 - val_loss: 0.7214 - val_acc: 0.7822 - f1: 0.6045 - 9s/epoch - 172ms/step\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00008: f1 improved from 0.60454 to 0.70126, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.2481 - acc: 0.9099 - val_loss: 0.4496 - val_acc: 0.8384 - f1: 0.7013 - 9s/epoch - 170ms/step\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00009: f1 (0.62746) did not improve from 0.70126\n",
            "50/50 - 8s - loss: 0.2089 - acc: 0.9249 - val_loss: 0.4887 - val_acc: 0.8267 - f1: 0.6275 - 8s/epoch - 155ms/step\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00010: f1 (0.62536) did not improve from 0.70126\n",
            "50/50 - 8s - loss: 0.1765 - acc: 0.9384 - val_loss: 0.6669 - val_acc: 0.7447 - f1: 0.6254 - 8s/epoch - 155ms/step\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00011: f1 improved from 0.70126 to 0.70682, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.1635 - acc: 0.9403 - val_loss: 0.5249 - val_acc: 0.8384 - f1: 0.7068 - 9s/epoch - 171ms/step\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00012: f1 (0.66565) did not improve from 0.70682\n",
            "50/50 - 8s - loss: 0.1187 - acc: 0.9553 - val_loss: 0.5770 - val_acc: 0.8080 - f1: 0.6657 - 8s/epoch - 156ms/step\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00013: f1 improved from 0.70682 to 0.72435, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.1073 - acc: 0.9629 - val_loss: 0.8878 - val_acc: 0.8197 - f1: 0.7244 - 9s/epoch - 172ms/step\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00014: f1 (0.49585) did not improve from 0.72435\n",
            "50/50 - 8s - loss: 0.0912 - acc: 0.9703 - val_loss: 1.7273 - val_acc: 0.7611 - f1: 0.4959 - 8s/epoch - 155ms/step\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00015: f1 improved from 0.72435 to 0.74008, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.0888 - acc: 0.9695 - val_loss: 1.0499 - val_acc: 0.8290 - f1: 0.7401 - 9s/epoch - 171ms/step\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00016: f1 improved from 0.74008 to 0.75436, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.0582 - acc: 0.9800 - val_loss: 0.6863 - val_acc: 0.8290 - f1: 0.7544 - 9s/epoch - 170ms/step\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00017: f1 (0.74686) did not improve from 0.75436\n",
            "50/50 - 8s - loss: 0.0485 - acc: 0.9844 - val_loss: 0.7401 - val_acc: 0.8384 - f1: 0.7469 - 8s/epoch - 156ms/step\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00018: f1 improved from 0.75436 to 0.76220, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.0342 - acc: 0.9887 - val_loss: 0.9303 - val_acc: 0.8384 - f1: 0.7622 - 9s/epoch - 170ms/step\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00019: f1 (0.72342) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0445 - acc: 0.9859 - val_loss: 0.9245 - val_acc: 0.7892 - f1: 0.7234 - 8s/epoch - 155ms/step\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00020: f1 (0.71044) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0398 - acc: 0.9856 - val_loss: 0.9992 - val_acc: 0.7892 - f1: 0.7104 - 8s/epoch - 155ms/step\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00021: f1 (0.68692) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0336 - acc: 0.9883 - val_loss: 1.3487 - val_acc: 0.7564 - f1: 0.6869 - 8s/epoch - 155ms/step\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00022: f1 (0.45719) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0368 - acc: 0.9884 - val_loss: 2.4613 - val_acc: 0.7869 - f1: 0.4572 - 8s/epoch - 155ms/step\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00023: f1 (0.55877) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0317 - acc: 0.9905 - val_loss: 1.3754 - val_acc: 0.8009 - f1: 0.5588 - 8s/epoch - 155ms/step\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00024: f1 (0.66951) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0329 - acc: 0.9891 - val_loss: 1.9030 - val_acc: 0.7939 - f1: 0.6695 - 8s/epoch - 155ms/step\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00025: f1 (0.74505) did not improve from 0.76220\n",
            "50/50 - 8s - loss: 0.0261 - acc: 0.9917 - val_loss: 1.1842 - val_acc: 0.8361 - f1: 0.7451 - 8s/epoch - 156ms/step\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00026: f1 improved from 0.76220 to 0.77139, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 8s - loss: 0.0171 - acc: 0.9948 - val_loss: 0.9857 - val_acc: 0.8501 - f1: 0.7714 - 8s/epoch - 170ms/step\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00027: f1 (0.75913) did not improve from 0.77139\n",
            "50/50 - 8s - loss: 0.0103 - acc: 0.9970 - val_loss: 0.9906 - val_acc: 0.8361 - f1: 0.7591 - 8s/epoch - 156ms/step\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00028: f1 (0.73454) did not improve from 0.77139\n",
            "50/50 - 8s - loss: 0.0098 - acc: 0.9972 - val_loss: 1.1000 - val_acc: 0.8244 - f1: 0.7345 - 8s/epoch - 155ms/step\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00029: f1 (0.75877) did not improve from 0.77139\n",
            "50/50 - 8s - loss: 0.0064 - acc: 0.9983 - val_loss: 1.2947 - val_acc: 0.8525 - f1: 0.7588 - 8s/epoch - 155ms/step\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00030: f1 (0.75785) did not improve from 0.77139\n",
            "50/50 - 8s - loss: 0.0031 - acc: 0.9995 - val_loss: 1.1723 - val_acc: 0.8501 - f1: 0.7579 - 8s/epoch - 155ms/step\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00031: f1 improved from 0.77139 to 0.78147, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 0.0012 - acc: 0.9998 - val_loss: 1.1888 - val_acc: 0.8618 - f1: 0.7815 - 9s/epoch - 170ms/step\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00032: f1 improved from 0.78147 to 0.79070, saving model to /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights\n",
            "50/50 - 9s - loss: 8.9573e-04 - acc: 1.0000 - val_loss: 1.1506 - val_acc: 0.8595 - f1: 0.7907 - 9s/epoch - 170ms/step\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00033: f1 (0.78224) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 4.5373e-04 - acc: 1.0000 - val_loss: 1.2148 - val_acc: 0.8571 - f1: 0.7822 - 8s/epoch - 155ms/step\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 1s 37ms/step\n",
            "\n",
            "Epoch 00034: f1 (0.78052) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 3.8537e-04 - acc: 1.0000 - val_loss: 1.2347 - val_acc: 0.8595 - f1: 0.7805 - 8s/epoch - 155ms/step\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00035: f1 (0.77279) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 3.2229e-04 - acc: 1.0000 - val_loss: 1.2210 - val_acc: 0.8501 - f1: 0.7728 - 8s/epoch - 155ms/step\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00036: f1 (0.77114) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 2.2218e-04 - acc: 1.0000 - val_loss: 1.2240 - val_acc: 0.8501 - f1: 0.7711 - 8s/epoch - 155ms/step\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00037: f1 (0.78307) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 2.0492e-04 - acc: 1.0000 - val_loss: 1.2276 - val_acc: 0.8525 - f1: 0.7831 - 8s/epoch - 155ms/step\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00038: f1 (0.78440) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.9014e-04 - acc: 1.0000 - val_loss: 1.2458 - val_acc: 0.8548 - f1: 0.7844 - 8s/epoch - 156ms/step\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00039: f1 (0.78307) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.8825e-04 - acc: 1.0000 - val_loss: 1.2364 - val_acc: 0.8525 - f1: 0.7831 - 8s/epoch - 155ms/step\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00040: f1 (0.78440) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.5705e-04 - acc: 1.0000 - val_loss: 1.2506 - val_acc: 0.8548 - f1: 0.7844 - 8s/epoch - 160ms/step\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00041: f1 (0.76277) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.8761e-04 - acc: 1.0000 - val_loss: 1.2515 - val_acc: 0.8431 - f1: 0.7628 - 8s/epoch - 155ms/step\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00042: f1 (0.77170) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.8995e-04 - acc: 1.0000 - val_loss: 1.2538 - val_acc: 0.8478 - f1: 0.7717 - 8s/epoch - 155ms/step\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00043: f1 (0.77717) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.5345e-04 - acc: 1.0000 - val_loss: 1.2644 - val_acc: 0.8501 - f1: 0.7772 - 8s/epoch - 155ms/step\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00044: f1 (0.77583) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.3588e-04 - acc: 1.0000 - val_loss: 1.2701 - val_acc: 0.8478 - f1: 0.7758 - 8s/epoch - 155ms/step\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00045: f1 (0.78307) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.1528e-04 - acc: 1.0000 - val_loss: 1.2793 - val_acc: 0.8525 - f1: 0.7831 - 8s/epoch - 156ms/step\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00046: f1 (0.78307) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.3651e-04 - acc: 1.0000 - val_loss: 1.2557 - val_acc: 0.8525 - f1: 0.7831 - 8s/epoch - 156ms/step\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00047: f1 (0.78574) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.2727e-04 - acc: 1.0000 - val_loss: 1.2862 - val_acc: 0.8571 - f1: 0.7857 - 8s/epoch - 155ms/step\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00048: f1 (0.78574) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.0150e-04 - acc: 1.0000 - val_loss: 1.3018 - val_acc: 0.8571 - f1: 0.7857 - 8s/epoch - 155ms/step\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00049: f1 (0.77985) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 9.0066e-05 - acc: 1.0000 - val_loss: 1.3045 - val_acc: 0.8548 - f1: 0.7798 - 8s/epoch - 155ms/step\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00050: f1 (0.77381) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.1353e-04 - acc: 1.0000 - val_loss: 1.3211 - val_acc: 0.8548 - f1: 0.7738 - 8s/epoch - 156ms/step\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00051: f1 (0.75985) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.3236e-04 - acc: 1.0000 - val_loss: 1.4059 - val_acc: 0.8478 - f1: 0.7598 - 8s/epoch - 155ms/step\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00052: f1 (0.77136) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 1.4867e-04 - acc: 1.0000 - val_loss: 1.3567 - val_acc: 0.8454 - f1: 0.7714 - 8s/epoch - 155ms/step\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 1s 35ms/step\n",
            "\n",
            "Epoch 00053: f1 (0.77758) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 8.6900e-05 - acc: 1.0000 - val_loss: 1.3276 - val_acc: 0.8501 - f1: 0.7776 - 8s/epoch - 155ms/step\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00054: f1 (0.77542) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 7.5848e-05 - acc: 1.0000 - val_loss: 1.3596 - val_acc: 0.8501 - f1: 0.7754 - 8s/epoch - 156ms/step\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00055: f1 (0.78036) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 7.7400e-05 - acc: 1.0000 - val_loss: 1.3628 - val_acc: 0.8501 - f1: 0.7804 - 8s/epoch - 155ms/step\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00056: f1 (0.78438) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 6.8123e-05 - acc: 1.0000 - val_loss: 1.3746 - val_acc: 0.8571 - f1: 0.7844 - 8s/epoch - 155ms/step\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00057: f1 (0.78303) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 5.7017e-05 - acc: 1.0000 - val_loss: 1.3813 - val_acc: 0.8548 - f1: 0.7830 - 8s/epoch - 156ms/step\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 1s 36ms/step\n",
            "\n",
            "Epoch 00058: f1 (0.77678) did not improve from 0.79070\n",
            "50/50 - 8s - loss: 6.1158e-05 - acc: 1.0000 - val_loss: 1.3843 - val_acc: 0.8501 - f1: 0.7768 - 8s/epoch - 156ms/step\n",
            "Epoch 58: early stopping\n",
            "Loading the best weights from file /content/drive/MyDrive/DLHProject/jobs/finetune_pretrain_20_weights_65sec_spectrogram/best_model.weights ...\n",
            "Predicting training data ...\n",
            "50/50 [==============================] - 2s 36ms/step\n",
            "Predicting validation data ...\n",
            "4/4 [==============================] - 0s 36ms/step\n",
            "Predicting test data ...\n",
            "14/14 [==============================] - 1s 76ms/step\n",
            "CPU times: user 4.04 s, sys: 708 ms, total: 4.75 s\n",
            "Wall time: 11min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python -m finetuning.trainer \\\n",
        "--job-dir $job_dir \\\n",
        "--train $train \\\n",
        "--test $test \\\n",
        "--weights-file $WEIGHTS_FILE \\\n",
        "--val-size 0.0625 \\\n",
        "--val-metric \"f1\" \\\n",
        "--arch \"resnet18_2d\" \\\n",
        "--batch-size 128 \\\n",
        "--epochs 200 \\\n",
        "--seed 2024 \\\n",
        "--verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSDq1xU1UHz"
      },
      "source": [
        "It took 11m 11s to run 50 epochs, as the paper authors have set up early stopping to end training if the loss on validation set does not decrease for more than 50 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEeqoHpGRVY-",
        "outputId": "f46d978a-6367-4044-f012-757f58266053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "environment.yml  finetune_runner.py  jupyter_notebooks\tpretraining  README.md\trequirements.txt\n",
            "example.ipynb\t finetuning\t     LICENSE\t\tproposal     report\ttransplant\n"
          ]
        }
      ],
      "source": [
        "! cd $job_dir\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_LYTdXZ3SCQI",
        "outputId": "31def02e-13e6-4738-dca0-aecf5f26abe9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"history\",\n  \"rows\": 58,\n  \"fields\": [\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 0,\n        \"max\": 57,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0,\n          5,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05110946621424448,\n        \"min\": 0.7399531006813049,\n        \"max\": 1.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.9995309114456176,\n          0.9799843430519104,\n          0.9917122721672058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1436025881690466,\n        \"min\": 0.1638794744417104,\n        \"max\": 0.7907034283218293,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          0.7104368893921971,\n          0.7758334072869396,\n          0.7775793650793651\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13554673921767463,\n        \"min\": 5.701653572032228e-05,\n        \"max\": 0.6676695346832275,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0.6676695346832275,\n          0.2887165546417236,\n          0.000322293897625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10578148478527649,\n        \"min\": 0.299765795469284,\n        \"max\": 0.8618267178535461,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          0.8196721076965332,\n          0.8430913090705872,\n          0.7447306513786316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3588084740066741,\n        \"min\": 0.4495745897293091,\n        \"max\": 2.461310863494873,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0.7148431539535522,\n          0.7704324722290039,\n          1.2210123538970947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "history"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ad3bc4ab-9c4e-40f9-8c77-14b23a6041bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>acc</th>\n",
              "      <th>f1</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.739953</td>\n",
              "      <td>0.414326</td>\n",
              "      <td>0.667670</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.714843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.841282</td>\n",
              "      <td>0.163879</td>\n",
              "      <td>0.432175</td>\n",
              "      <td>0.299766</td>\n",
              "      <td>1.823976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.855825</td>\n",
              "      <td>0.197550</td>\n",
              "      <td>0.383515</td>\n",
              "      <td>0.327869</td>\n",
              "      <td>1.641245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.875215</td>\n",
              "      <td>0.340952</td>\n",
              "      <td>0.342986</td>\n",
              "      <td>0.573770</td>\n",
              "      <td>1.465950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.884128</td>\n",
              "      <td>0.516218</td>\n",
              "      <td>0.312859</td>\n",
              "      <td>0.807963</td>\n",
              "      <td>0.702650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad3bc4ab-9c4e-40f9-8c77-14b23a6041bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad3bc4ab-9c4e-40f9-8c77-14b23a6041bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad3bc4ab-9c4e-40f9-8c77-14b23a6041bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8ddd296-0794-431d-8bd1-4ce076fd8c32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8ddd296-0794-431d-8bd1-4ce076fd8c32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8ddd296-0794-431d-8bd1-4ce076fd8c32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   epoch       acc        f1      loss   val_acc  val_loss\n",
              "0      0  0.739953  0.414326  0.667670  0.688525  0.714843\n",
              "1      1  0.841282  0.163879  0.432175  0.299766  1.823976\n",
              "2      2  0.855825  0.197550  0.383515  0.327869  1.641245\n",
              "3      3  0.875215  0.340952  0.342986  0.573770  1.465950\n",
              "4      4  0.884128  0.516218  0.312859  0.807963  0.702650"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "history = pd.read_csv(job_dir + '/history.csv')\n",
        "history.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "fqTE6OncScQs",
        "outputId": "b18b7e1f-c84d-4521-e68e-b180be355e40"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "_ = plt.plot(history['epoch'], history['f1'], color='tab:red')\n",
        "_ = plt.xlabel('Epoch')\n",
        "_ = plt.ylabel('Validation F1')\n",
        "ax = plt.gca()\n",
        "_ = ax.set_xlim([0, 140])\n",
        "_ = ax.set_ylim([0.5, 1.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkSo7dInODmp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
