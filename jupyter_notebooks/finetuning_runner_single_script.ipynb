{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKyaFxKpwDF9"
      },
      "source": [
        "Instructions to run the `finetune_runner.py` script to generate additional fine-tuning results for each of the 3 weights scenarios:\n",
        "\n",
        "1. `random`\n",
        "2. `10` (10% pre-train weights)\n",
        "3. `20` (20% pre-train weights)\n",
        "\n",
        "Data refers to the percentage of patients in the _Icentia11K_ dataset.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Prerequisites:\n",
        "\n",
        "- Google Colab Pro\n",
        "- V100 GPU\n",
        "\n",
        "\n",
        "### Select instance\n",
        "\n",
        "Select V100 GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eDeQUIx2AdP"
      },
      "source": [
        "### Clone Git repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoHTm9Fz2BM9"
      },
      "outputs": [],
      "source": [
        "%cd /root\n",
        "! git clone https://github.com/myles-i/DLH_TransferLearning.git\n",
        "%cd DLH_TransferLearning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPw1-7Fw38el"
      },
      "source": [
        "### Install dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLPArTJF4CbC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvYiiuY919T5"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LGFwWzAwAux"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "913MhsuXxIXx"
      },
      "source": [
        "### Determine path to data and job directories on Drive\n",
        "\n",
        "Example for me:\n",
        "\n",
        "`/content/drive/MyDrive/DLHProject`\n",
        "\n",
        "where `DLHProject` is the name of my shortcut for the shared folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IpLm1B7xkHA"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = '/content/drive/MyDrive/DLHProject'\n",
        "DATA_DIR = PROJECT_DIR + '/data'\n",
        "JOB_DIR = PROJECT_DIR + '/jobs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dzwyLJsp1Nin"
      },
      "outputs": [],
      "source": [
        "# setup top level directory paths\n",
        "PROJECT_DIR = '/content/drive/MyDrive/DLHProject'\n",
        "DATA_DIR = PROJECT_DIR + '/data'\n",
        "JOB_DIR = PROJECT_DIR + '/jobs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VbDytx2jWLD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dry_run = True # change this to False once you have verified everything looks good\n",
        "\n",
        "# finetune/pretraining data paths (can vary depending on model used)\n",
        "arch = \"resnet18_2d\"\n",
        "PHYSIONET_TRAIN = DATA_DIR + \"/physionet_finetune_spectrogram/physionet_train.pkl\"\n",
        "PHYSIONET_TEST = DATA_DIR + \"/physionet_finetune_spectrogram/physionet_test.pkl\"\n",
        "PRETRAIN_BASE =JOB_DIR + \"/spectrogram/pretraining/min_normalization_16epochs_to_20percent\"\n",
        "FINETUNE_BASE =JOB_DIR + \"/spectrogram/finetuning/min_normalization_16epochs_to_20percent\"\n",
        "os.makedirs(FINETUNE_BASE, exist_ok=True)\n",
        "\n",
        "# define which combinations of runs to do\n",
        "weight_types = {\"random\",\n",
        "                \"10\",\n",
        "                \"20\"}\n",
        "\n",
        "weight_files = {\"\",\n",
        "                PRETRAIN_BASE + \"/epoch_08/model.weights\",\n",
        "                PRETRAIN_BASE + \"/epoch_16/model.weights\"}\n",
        "\n",
        "\n",
        "os.makedirs(FINETUNE_BASE, exist_ok=True)\n",
        "for weight_type, weight_file in zip(weight_types, weight_files):\n",
        "  # lets verify all data/weight files exist\n",
        "  assert os.path.exists(PHYSIONET_TRAIN), \"PHYSIONET_TRAIN does not exist\"\n",
        "  assert os.path.exists(PHYSIONET_TEST), \"PHYSIONET_TEST does not exist\"\n",
        "  assert os.path.exists(weight_file), \"weight_file does not exist\"\n",
        "\n",
        "  ! seq 10 10 100 | xargs -P 1 -I {} python finetune_runner.py \\\n",
        "  --arch {arch} \\\n",
        "  --weights-type {weight_type} \\\n",
        "  --weights-file {weight_file} \\\n",
        "  --job-base-dir /content/drive/MyDrive/DLHProject/jobs/spectrogram \\\n",
        "  --train {PHYSIONET_TRAIN} \\\n",
        "  --test {PHYSIONET_TEST} \\\n",
        "  --batch-size 128 \\\n",
        "  --epochs 200 \\\n",
        "  --seed '{}' \\\n",
        "  --dryrun {dry_run}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
