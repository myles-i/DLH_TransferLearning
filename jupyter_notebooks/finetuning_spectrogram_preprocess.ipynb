{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7WQ_wxvQ29B",
        "outputId": "8d623bdf-118e-4a2f-9081-cb2c4ae8b1ab"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6B3mL6KTF2x",
        "outputId": "a7ba624e-8a61-4c87-d1fa-2d3c62cf72fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/myles/uiuc/DLH/ecg-transfer-learning\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# define input and output dirs\n",
        "PHYSIONET_DATA_DIR = \"/content/drive/MyDrive/DLHProject/data/physionet_finetune\"\n",
        "PHYSIONET_SPECTOGRAM_OUT_DIR = \"/content/drive/MyDrive/DLHProject/data/physionet_finetune_spectrogram\"\n",
        "os.makedirs(PHYSIONET_SPECTOGRAM_OUT_DIR, exist_ok=True)\n",
        "\n",
        "# move to my repo\n",
        "REPO_DIR = \"/content/drive/MyDrive/DLHProject/Mylesgitrepo\"\n",
        "%cd \"{REPO_DIR}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75dsvOPVS5jJ"
      },
      "source": [
        "Install project requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSBh_JnJTr7O"
      },
      "source": [
        "Next we want to prepare the train and test datasets. Before we generate them, we first make sure to save them to the right destination. Otherwise we will write data to the git repository which we don't want. Thus, we spend the next few cells figuring out where to save these files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vWkS3rr0VUWF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-25 18:18:53.197252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from finetuning import datasets\n",
        "from finetuning.utils import train_test_split\n",
        "from transplant.utils import save_pkl, load_pkl\n",
        "import numpy as np\n",
        "from transplant.datasets.icentia11k_spectogram import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EYANbqXGShJi"
      },
      "outputs": [],
      "source": [
        "# load the data - this is already preprocessed (resampled to 250Hz, normalized zero mean/stddev)\n",
        "train_set = load_pkl(f'{PHYSIONET_DATA_DIR}/physionet_train.pkl')\n",
        "test_set = load_pkl(f'{PHYSIONET_DATA_DIR}/physionet_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set keys:  dict_keys(['x', 'y', 'record_ids', 'classes'])\n",
            "train_set[x] shape:  (6822, 16384, 1)\n",
            "test_set keys:  dict_keys(['x', 'y', 'record_ids', 'classes'])\n",
            "test_set[x] shape:  (1706, 16384, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"train_set keys: \", train_set.keys())\n",
        "print(\"train_set[x] shape: \", train_set['x'].shape)\n",
        "\n",
        "print(\"test_set keys: \", test_set.keys())\n",
        "print(\"test_set[x] shape: \", test_set['x'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing test set...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at iteration  0 of  1706\n",
            "at iteration  500 of  1706\n",
            "at iteration  1000 of  1706\n",
            "at iteration  1500 of  1706\n",
            "test_set shape:  (1706, 16384, 1)\n",
            "test_set spectrogram shape:  (1706, 128, 512, 1)\n",
            "Processing train set...\n",
            "at iteration  0 of  6822\n",
            "at iteration  500 of  6822\n",
            "at iteration  1000 of  6822\n",
            "at iteration  1500 of  6822\n",
            "at iteration  2000 of  6822\n",
            "at iteration  2500 of  6822\n",
            "at iteration  3000 of  6822\n",
            "at iteration  3500 of  6822\n",
            "at iteration  4000 of  6822\n",
            "at iteration  4500 of  6822\n",
            "at iteration  5000 of  6822\n",
            "at iteration  5500 of  6822\n",
            "at iteration  6000 of  6822\n",
            "at iteration  6500 of  6822\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def preprocess_data_to_spectrogram(data):\n",
        "    tempdata = []\n",
        "    for i in range(data['x'].shape[0]):\n",
        "        #run and add a dimunesion at 0th place\n",
        "        tempdata.append( np.expand_dims(spectogram_preprocessor(np.squeeze(data['x'][i]),\n",
        "                                    window_size = 256, \n",
        "                                    stride = 32,\n",
        "                                    n_freqs = 128,\n",
        "                                    fs = 250.,\n",
        "                                    ref = 1), axis=0))\n",
        "        # print progress every 500\n",
        "        if i % 500 == 0:\n",
        "            print(\"at iteration \", i, \"of \", data['x'].shape[0])\n",
        "    \n",
        "    # construct the data\n",
        "    new_data = {}\n",
        "    new_data['x'] = np.concatenate(tempdata, axis=0)\n",
        "    new_data['y'] = data['y']\n",
        "    new_data['record_ids'] = data['record_ids']\n",
        "    new_data['classes'] = data['classes']\n",
        "    \n",
        "    return new_data\n",
        "# loop through 0th dim of test_set['x'] and run preprocessing on all of them\n",
        "\n",
        "print('Processing test set...')\n",
        "test_set_spectrogram = preprocess_data_to_spectrogram(test_set)\n",
        "print(\"test_set shape: \", test_set['x'].shape)\n",
        "print(\"test_set spectrogram shape: \", test_set_spectrogram['x'].shape)\n",
        "save_pkl(f'{PHYSIONET_SPECTOGRAM_OUT_DIR}/physionet_test.pkl', **test_set_spectrogram)\n",
        "\n",
        "\n",
        "\n",
        "print('Processing train set...')\n",
        "train_set_spectrogram= preprocess_data_to_spectrogram(train_set)\n",
        "print(\"train_set shape: \", train_set['x'].shape)\n",
        "print(\"train_set spectrogram shape: \", train_set_spectrogram['x'].shape)\n",
        "save_pkl(f'{PHYSIONET_SPECTOGRAM_OUT_DIR}/physionet_train.pkl', **train_set_spectrogram)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'load_pkl' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_set_spectrogram \u001b[38;5;241m=\u001b[39m\u001b[43mload_pkl\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPHYSIONET_SPECTOGRAM_OUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/physionet_test.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(test_set_spectrogram))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_set_spectrogram\u001b[38;5;241m.\u001b[39mkeys())\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_pkl' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "test_set_spectrogram =load_pkl(f'{PHYSIONET_SPECTOGRAM_OUT_DIR}/physionet_test.pkl')\n",
        "print(type(test_set_spectrogram))\n",
        "print(test_set_spectrogram.keys())\n",
        "print(test_set_spectrogram['x'][0].shape)\n",
        "# test_set_spectrogram is an array of elements who individually are of size (128,512). Lets concatenate these so its (n,128,512)\n",
        "import matplotlib.pyplot as plt\n",
        "# print one of the spectrograms\n",
        "# x and y are EagerTensor\n",
        "# lets plot it\n",
        "x = test_set_spectrogram['x'][0];\n",
        "# add dimension up front\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "ax.imshow(x, cmap='viridis')\n",
        "ax.set_title(f\"Sample spectogram of shape {x.shape}\")\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# zoom into last 200 slices\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LFyyyKMWXQ7"
      },
      "source": [
        "\n",
        "The above took about <> time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "467mGk0LXQQ2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
